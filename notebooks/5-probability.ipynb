{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/5-probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTOLgsbN69-P"
   },
   "source": [
    "# Probability & Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqUB9FTRAxd-"
   },
   "source": [
    "This class, *Probability & Information Theory*, introduces the mathematical fields that enable us to quantify uncertainty as well as to make predictions despite uncertainty. These fields are essential because machine learning algorithms are both trained by imperfect data and deployed into noisy, real-world scenarios they haven’t encountered before. \n",
    "\n",
    "Through the measured exposition of theory paired with interactive examples, you’ll develop a working understanding of variables, probability distributions, metrics for assessing distributions, and graphical models. You’ll also learn how to use information theory to measure how much meaningful signal there is within some given data. The content covered in this class is itself foundational for several other classes in the *Machine Learning Foundations* series, especially *Intro to Statistics* and *Optimization*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4tBvI88BheF"
   },
   "source": [
    "Over the course of studying this topic, you'll: \n",
    "\n",
    "* Develop an understanding of what’s going on beneath the hood of predictive statistical models and machine learning algorithms, including those used for deep learning. \n",
    "* Understand the appropriate variable type and probability distribution for representing a given class of data, as well as the standard techniques for assessing the relationships between distributions.\n",
    "* Apply information theory to quantify the proportion of valuable signal that’s present amongst the noise of a given probability distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z68nQ0ekCYhF"
   },
   "source": [
    "**Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's [Machine Learning Foundations](https://github.com/jonkrohn/ML-foundations) series, which offer detail on the following:**\n",
    "\n",
    "*Segment 1: Introduction to Probability*\n",
    "* A Brief History of Probability Theory: Frequentists vs Bayesians\n",
    "* Applications of Probability to Machine Learning\n",
    "* Random vs Fixed Variables\n",
    "* Discrete vs Continuous Variables\n",
    "* Probability Mass and Probability Density Functions\n",
    "* Marginal and Conditional Probabilities\n",
    "* Expected Value\n",
    "* Measures of Central Tendency: Mean, Median, and Mode\n",
    "* Quantiles: Quartiles, Deciles, and Percentiles\n",
    "* The Box-and-Whisker Plot\n",
    "* Variance and Standard Deviation\n",
    "* Covariance and Correlation\n",
    "* Directed and Undirected Graphical Models\n",
    "\n",
    "*Segment 2: Distributions in Machine Learning*\n",
    "* Uniform\n",
    "* Gaussian: Normal and Standard Normal\n",
    "* Log-Normal\n",
    "* Poisson\n",
    "* Exponential and Laplace\n",
    "* Bernoulli, Multinomial and Multinoulli\n",
    "* Mixtures of Distributions\n",
    "* The Central Limit Theorem\n",
    "\n",
    "*Segment 3: Information Theory*\n",
    "* What Information Theory Is\n",
    "* Nats vs Bits\n",
    "* Shannon vs Differential Entropy\n",
    "* Kullback-Liebler Divergence\n",
    "* Cross-Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 1: Introduction to Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Probability Theory Is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a fair coin, which is equally likely to come up heads (H) or tails (T)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In instances like this, where the two outcomes are equally likely, we can use probability theory to express the likelihood of a particular **event** by comparing it with the **sample space** (the set of all possible outcomes; can be denoted as $\\Omega$): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(\\text{event}) = \\frac{\\text{# of outcomes of event}}{\\text{# of outcomes in }\\Omega} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're only flipping the coin once, then there are only two possible outcomes in the sample space $\\Omega$: it will either be H or T (using set notation, we could write this as $\\Omega$ = {H, T})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore: $$ P(H) = \\frac{1}{2} = 0.5 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equally: $$ P(T) = \\frac{1}{2} = 0.5 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a separate example, consider drawing a single card from a standard deck of 52 playing cards. In this case, the number of possible outcomes in the sample space $\\Omega$ is 52. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one ace of spades in the deck, so the probability of drawing it is: $$ P(\\text{ace of spades}) = \\frac{1}{52} \\approx 0.019 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast there are four aces, so the probability of drawing an ace is: $$ P(\\text{ace}) = \\frac{4}{52} \\approx 0.077 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional examples: \n",
    "$$ P(\\text{spade}) = \\frac{13}{52} = 0.25 $$\n",
    "$$ P(\\text{ace OR spade}) = \\frac{16}{52} \\approx 0.307 $$\n",
    "$$ P(\\text{card}) = \\frac{52}{52} = 1 $$\n",
    "$$ P(\\text{turnip}) = \\frac{0}{52} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple independent observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to coin flipping to illustrate situations where we have an event consisting of multiple independent observations. For example, the probability of throwing two consecutive heads is: $$ P(\\text{HH}) = \\frac{1}{4} = 0.25 $$ ...because there is one HH event in the sample set of four possible events ($\\Omega$ = {HH, HT, TH, TT})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the probability of throwing *three* consecutive heads is: $$ P(\\text{HHH}) = \\frac{1}{8} = 0.125 $$ ...because there is one HHH event in the sample set of eight possible events ($\\Omega$ = {HHH, HHT, HTH, THH, HTT, THT, TTH, TTT})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As final examples, the probability of throwing exactly two heads in three tosses is $ P = \\frac{3}{8} = 0.375 $ while the probability of throwing at least two heads in three tosses is $ P = \\frac{4}{8} = 0.5 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to combine probabilities, we can multiply them. So the probability of throwing five consecutive heads, for example, is the product of probabilities we've already calculated: $$ P(\\text{HHHHH}) = P(\\text{HH}) \\times P(\\text{HHH}) = \\frac{1}{4} \\times \\frac{1}{8} = \\frac{1}{32} \\approx 0.031 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinatorics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Combinatorics* is a field of mathematics devoted to counting. We can use *combinatorials* (e.g., $4! = 4 \\times 3 \\times 2 \\times 1 = 24$), which feature prominently in combinatorics, to calculate probabilities instead of painstakingly determining all of the members of the sample space $\\Omega$ and counting subsets within $\\Omega$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, we can calculate the number of outcomes of an event using the \"number of combinations\" equation: $$ {n \\choose k} = \\frac{n!}{k!(n - k)!} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side of the equation is read \"$n$ choose $k$\" and is most quickly understood via an example: If we have three coin flips, $n = 3$, and if we're interested in the number of ways to get two head flips (or two tail flips, for that matter), $k = 2$. We would read this as \"3 choose 2\" and calculate it as:\n",
    "$$ {n \\choose k} = {3 \\choose 2} = \\frac{3!}{2!(3 - 2)!} = \\frac{3!}{(2!)(1!)} = \\frac{3 \\times 2 \\times 1}{(2 \\times 1)(1)} = \\frac{6}{(2)(1)} = \\frac{6}{2} = 3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provide us with the numerator for event-probability equation from above: $$ P(\\text{event}) = \\frac{\\text{# of outcomes of event}}{\\text{# of outcomes in }\\Omega} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of coin-flipping, the denominator can be calculated with $2^n$ (where $n$ is again the number of coin flips), so: $$ \\frac{\\text{# of outcomes of event}}{\\text{# of outcomes in }\\Omega} = \\frac{3}{2^n} = \\frac{3}{2^3} = \\frac{3}{8} \\approx 0.375 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**:\n",
    "\n",
    "1. What is the probability of drawing the ace of spades twice in a row? (Assume that any card drawn on the first draw will be put back in the deck before the second draw.)\n",
    "2. You draw a card from a deck of cards. After replacing the drawn card back in the deck and shuffling thoroughly, what is the probability of drawing the same card again? \n",
    "3. Use $n \\choose k$ to calculate the probability of throwing three heads in five coin tosses.\n",
    "4. Create a Python method that solves exercise 1 and incorporates the $n \\choose k$ formula $\\frac{n!}{k!(n - k)!}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler alert: Solutions are below so scroll carefully..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $$ P(\\text{ace of spades}) \\times P(\\text{ace of spades}) = \\bigg(\\frac{1}{52}\\bigg)^2 = \\frac{1}{2704} = 0.00037 = 0.037\\% $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $$ P(\\text{any card}) = \\frac{52}{52} = 1 $$\n",
    "$$ P(\\text{same card as first draw}) = \\frac{1}{52} \\approx 0.019 $$\n",
    "$$ P(\\text{any card})P(\\text{same card as first draw}) = (1)(\\frac{1}{52}) = \\frac{1}{52} \\approx 0.019$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. $$ {n \\choose k} = {5 \\choose 3} = \\frac{5!}{3!(5 - 3)!} = \\frac{5!}{(3!)(2!)} = \\frac{5 \\times 4 \\times 3 \\times 2 \\times 1}{(3 \\times 2 \\times 1)(2 \\times 1)} = \\frac{120}{(6)(2)} = \\frac{120}{12} = 10 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P = \\frac{10}{2^n} = \\frac{10}{2^5} = \\frac{10}{32} = 0.3125 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinflip_prob(n, k):\n",
    "    n_choose_k = factorial(n)/(factorial(k)*factorial(n-k))\n",
    "    return n_choose_k/2**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coinflip_prob(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Law of Large Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a fair coin should land heads up 50% of the time, as we've seen above, with small sample sizes, there is a non-trivial possibility that in a given experiment we could flip heads on all of the tosses. For example, we've calculated that there's a 3.1% chance that we'll get heads on every toss in a small five-toss experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **law or large numbers** states that the more experiments we run, the closer we will tend to get to the expected probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some code to examine this in practice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]) # number of coin tosses per experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss the `binomial()` method in detail in *Segment 2*. For now it suffices to think of its two arguments as *number of coin flips in experiment* and *probability of heads*, while it returns the number of flips that are heads in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 9, 13, 34, 65, 144, 259, 511, 1038, 2033]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads_count = [np.random.binomial(n, 0.5) for n in ns]\n",
    "heads_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 1.        , 0.625     , 0.5625    , 0.40625   ,\n",
       "       0.53125   , 0.5078125 , 0.5625    , 0.50585938, 0.49902344,\n",
       "       0.50683594, 0.49633789])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_heads = heads_count/ns\n",
    "proportion_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Number of coin flips in experiment')\n",
    "plt.ylabel('Proportion of flips that are heads')\n",
    "plt.axhline(0.5, color='orange')\n",
    "_ = ax.scatter(ns, proportion_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important concept at this juncture is the **gambler's fallacy**. It is a common misconception that the law of large numbers dictates that if, say, five heads have been flipped in a row, then the probability of tails is higher on the sixth flip. In fact, probability theory holds that each coin flip is completely independent of all others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To capitalize on this misunderstanding, roulette tables at casinos often have prominent displays tracking the history of red vs black even though there's a 47.4% chance of each, on every single spin of the roulette wheel, no matter what happened on preceding spins.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4toL+odzCdics69uQ9+W4",
   "include_colab_link": true,
   "name": "5-probability.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
