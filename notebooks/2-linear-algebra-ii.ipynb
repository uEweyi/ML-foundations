{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/2-linear-algebra-ii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTOLgsbN69-P"
   },
   "source": [
    "# Linear Algebra II: Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqUB9FTRAxd-"
   },
   "source": [
    "This topic, *Linear Algebra II: Matrix Operations*, builds on the basics of linear algebra. It is essential because these intermediate-level manipulations of tensors lie at the heart of most machine learning approaches and are especially predominant in deep learning. \n",
    "\n",
    "Through the measured exposition of theory paired with interactive examples, you’ll develop an understanding of how linear algebra is used to solve for unknown values in high-dimensional spaces as well as to reduce the dimensionality of complex spaces. The content covered in this topic is itself foundational for several other topics in the *Machine Learning Foundations* series, especially *Probability & Information Theory* and *Optimization*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4tBvI88BheF"
   },
   "source": [
    "Over the course of studying this topic, you'll: \n",
    "\n",
    "* Develop a geometric intuition of what’s going on beneath the hood of machine learning algorithms, including those used for deep learning. \n",
    "* Be able to more intimately grasp the details of machine learning papers as well as all of the other subjects that underlie ML, including calculus, statistics, and optimization algorithms. \n",
    "* Reduce the dimensionalty of complex spaces down to their most informative elements with techniques such as eigendecomposition, singular value decomposition, and principal components analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z68nQ0ekCYhF"
   },
   "source": [
    "**Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's [Machine Learning Foundations](https://github.com/jonkrohn/ML-foundations) series, which offer detail on the following:**\n",
    "\n",
    "*Review of Matrix Properties*\n",
    "\n",
    "* Modern Linear Algebra Applications\n",
    "* Tensors, Vectors, and Norms\n",
    "* Matrix Multiplication\n",
    "* Matrix Inversion\n",
    "* Identity, Diagonal and Orthogonal Matrices\n",
    "\n",
    "*Segment 2: Eigendecomposition*\n",
    "\n",
    "* Matrix Determinants\n",
    "* Eigenvectors\n",
    "* Eigenvalues\n",
    "* Matrix Decomposition \n",
    "* Applications of Eigendecomposition\n",
    "\n",
    "*Segment 3: Matrix Operations for Machine Learning*\n",
    "\n",
    "* Singular Value Decomposition (SVD)\n",
    "* The Moore-Penrose Pseudoinverse\n",
    "* The Trace Operator\n",
    "* Principal Component Analysis (PCA): A Simple Machine Learning Algorithm\n",
    "* Resources for Further Study of Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty8zFJj9j3Ui"
   },
   "source": [
    "## Segment 1: Review of Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixvqsCeFj3Uj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0LgmflFj3Um"
   },
   "source": [
    "### Vector Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25,  2,  5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([25, 2, 5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvLQEylJj3Un",
    "outputId": "201ba11e-2904-4084-e9d9-b865072e6e93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2,  5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[25, 2, 5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6XtfKZ8j3Ut",
    "outputId": "3ce3d51d-a5ca-4513-9296-d69e8d45e8cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25],\n",
       "       [ 2],\n",
       "       [ 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IN1_aSVQj3Uw",
    "outputId": "e37e7b5c-ed16-4955-faa0-e76ce1d7f112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-_nrgesj3U4",
    "outputId": "4917c288-7b5d-47b2-a878-e3da375f58b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  2,  5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_p = torch.tensor([25, 2, 5])\n",
    "x_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0YuG9Pmj3U6",
    "outputId": "734a426f-6503-4298-845a-e936513e8066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  2,  5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_p.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_bRLc5wj3U8",
    "outputId": "2530e985-5684-433d-c576-603916d2daec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25],\n",
       "        [ 2],\n",
       "        [ 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_p.view(3, 1) # \"view\" because we're changing output but not the way x is stored in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llPpXVPHj3U_"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43tlq2huj3U_"
   },
   "source": [
    "## $L^2$ Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF1B2qL1j3VA",
    "outputId": "a24057fd-93a3-4513-b95c-9eaa8220045d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2,  5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SW2iYHE8j3VC",
    "outputId": "26ebcfff-3220-4351-fa90-e2c21adeb6b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.573423705088842"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(25**2 + 2**2 + 5**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGiMFU0pj3VE",
    "outputId": "165d1e73-3514-4c3b-c955-24012c2b2b2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.573423705088842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YBk8ta2j3VI"
   },
   "source": [
    "So, if units in this 3-dimensional vector space are meters, then the vector $x$ has a length of 25.6m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjS4_w_Rj3VI"
   },
   "outputs": [],
   "source": [
    "# the following line of code will fail because torch.norm() requires input to be float not integer\n",
    "# torch.norm(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgadi8SFj3VK",
    "outputId": "a8819539-9dbe-4bb5-dbde-943ef6c1d789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.5734)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.tensor([25, 2, 5.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHti3Xslj3VM"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xDLTPutj3VN"
   },
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fep93KC7j3VN",
    "outputId": "daa76d80-2294-4994-c268-0a6274d183a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[25, 2], [5, 26], [3, 7]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_yMqWdSj3VP",
    "outputId": "8b2f690e-a383-41b3-fe4b-c8fa8b6d4735"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDkn2n92j3VX",
    "outputId": "0491c341-f2ab-42d9-ae41-306c55b292cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  2],\n",
       "        [ 5, 26],\n",
       "        [ 3,  7]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p = torch.tensor([[25, 2], [5, 26], [3, 7]])\n",
    "X_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzpKBCqKj3VY",
    "outputId": "3ea34673-a489-418e-a900-f8b33ce4f758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jL7I-iWj3Vg"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pC1rWTlVj3Vg"
   },
   "source": [
    "### Matrix Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srh333wTj3Vg",
    "outputId": "faa97c11-28ce-4a47-f2fc-d4e80e30c8c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7siMBsRj3Vi",
    "outputId": "8d2b7052-32d3-4e18-a47d-71f7721099cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5,  3],\n",
       "       [ 2, 26,  7]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF3iqTkUj3Vk",
    "outputId": "0289f154-12bd-4cd7-e448-311260d662cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  5,  3],\n",
       "        [ 2, 26,  7]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXo5iD5Xj3Vm"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loFYZ-pXj3Vm"
   },
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrHCDYrzj3Vm"
   },
   "source": [
    "Scalars are applied to each element of matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yf3WIZ6Jj3Vn",
    "outputId": "d1771acb-2ace-4539-8ca6-3f1c474b7cb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  6],\n",
       "       [15, 78],\n",
       "       [ 9, 21]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pk-lY78Nj3Vp",
    "outputId": "3a677d4d-9921-42bf-c631-6e38fac78e33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78,  9],\n",
       "       [18, 81],\n",
       "       [12, 24]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_sJ0NI8j3Vq",
    "outputId": "10874a31-e67d-47f7-cd9a-25e686206b37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[75,  6],\n",
       "        [15, 78],\n",
       "        [ 9, 21]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jebPN-iPj3Vs",
    "outputId": "81de14ff-554f-444c-ec7f-eb2e4bfbdea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[78,  9],\n",
       "        [18, 81],\n",
       "        [12, 24]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p*3+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-a4o6abYj3Vu"
   },
   "source": [
    "Using the multiplication operator on two tensors of the same size in PyTorch (or Numpy or TensorFlow) applies element-wise operations. This is the **Hadamard product** (denoted by the $\\odot$ operator, e.g., $A \\odot B$) *not* **matrix multiplication**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtRT2V0cj3Vu",
    "outputId": "dc363187-2e45-43b7-e308-098f90a68649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LLJYG8MIj3Vw",
    "outputId": "b3c07ca8-bec3-4400-ba59-e930d578abb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtXoLfKbj3Vx",
    "outputId": "98ccafbb-a46f-4b7f-e9d2-b6f51cf96dba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75,   8],\n",
       "       [ 25, 156],\n",
       "       [ 21,  56]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8T09ZO4ij3Vz",
    "outputId": "573b4ae2-9ca9-49c9-a2b8-086a83ef4af6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_p = torch.tensor([[3, 4], [5, 6], [7, 8]])\n",
    "A_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBadBzQJj3V1",
    "outputId": "4deeea6d-e38b-43f0-8352-561cd540b366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 75,   8],\n",
       "        [ 25, 156],\n",
       "        [ 21,  56]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p * A_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_4kMhF7j3V4"
   },
   "source": [
    "Matrix multiplication with a vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAJEstCLj3V5",
    "outputId": "1294b0db-7eed-40dd-a98a-8834e248b2d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([1, 2])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOxK6XEXj3V8",
    "outputId": "d219f59e-304f-4f02-e80b-b79cdf93cb9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 17, 23])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, b) # even though technically dot products is between 2 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Y3Ohltbj3V-",
    "outputId": "10c44bd8-6249-4f87-e505-37f97f53d546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_p = torch.tensor([1, 2])\n",
    "b_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LioexYZ_j3WB",
    "outputId": "9a565e69-359a-419b-faf9-1af930e1fa65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 17, 23])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A_p, b_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Wa5CB28j3WC"
   },
   "source": [
    "Matrix multiplication with two matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8ZXM-T4j3WD",
    "outputId": "e43c31b0-b959-448d-e33f-7a1e5950e2b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9],\n",
       "       [2, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1, 9], [2, 0]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xE0DA5Xrj3WF",
    "outputId": "d56f767e-6057-4f5f-8799-9821e9a39210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B) # note first column is same as Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBvYO9jFj3WH",
    "outputId": "07ad5cfa-6827-45a7-f416-8c9c80cd7b7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 9],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_p = torch.tensor([[1, 9], [2, 0]])\n",
    "B_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2nEnn3Mj3WI",
    "outputId": "c22cb10a-d2b3-4e1c-cc09-c5e01ff7a36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 27],\n",
       "        [17, 45],\n",
       "        [23, 63]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A_p, B_p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCFqu8LWj3WJ"
   },
   "source": [
    "### Matrix Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hhr16-XVj3WK",
    "outputId": "9e0aa4f3-a438-4d73-a8e8-b63535d94ba1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  2],\n",
       "       [-5, -3]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[4, 2], [-5, -3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIGmFK9oj3WM",
    "outputId": "6f685f9b-f1cb-49ee-8f27-52a644d24a76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1. ],\n",
       "       [-2.5, -2. ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinv = np.linalg.inv(X)\n",
    "Xinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWEFauNsj3WO",
    "outputId": "517fc8a2-de81-4341-d761-68c866a9be62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, -7])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([4, -7])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egKyXcZhj3WR",
    "outputId": "1f6f59e4-82d3-4a65-8d2e-251f5dc5da98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  4.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.dot(Xinv, y)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that $y = Xw$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4., -7.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jro-lItLj3WT",
    "outputId": "417d4901-675b-4641-a791-f48a088ac0b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  2.],\n",
       "        [-5., -3.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p = torch.tensor([[4, 2], [-5, -3.]]) # note that torch.inverse() requires floats\n",
    "X_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4HfI57Nj3WW",
    "outputId": "6863c818-6832-4ff3-e78d-126fe19df83f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  1.0000],\n",
       "        [-2.5000, -2.0000]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinv_p = torch.inverse(X_p)\n",
    "Xinv_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dy88LRcyj3WY",
    "outputId": "95a6c7e0-c066-4ee1-cec3-5e7dfbf4a813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., -7.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = torch.tensor([4, -7.])\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wB3r-ggj3Wa",
    "outputId": "3cb28b7a-75cc-4a7b-d707-399cd171361b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  4.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_p = torch.matmul(Xinv_p, y_p)\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4., -7.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(X_p, w_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWXikiwFj3Wb"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4XpcVX2j3Wc"
   },
   "source": [
    "## Segment 2: Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F44cMjS8j3Wc"
   },
   "source": [
    "### 2x2 Matrix Determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjsXPZEsj3Wc",
    "outputId": "4c12d175-8993-4c94-b590-8602378c8663"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tg8BDzOj3We",
    "outputId": "276a9faf-2755-4277-c4c2-16fc8afb48bf"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87wpY5hUj3Wg"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5jp6vkNj3Wg",
    "outputId": "365f8b28-32a5-479a-ab8c-a2b0b2c67219"
   },
   "outputs": [],
   "source": [
    "N = np.array([[-4, 1], [-8, 2]])\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejdkdN7Lj3Wi",
    "outputId": "8ecb038d-ad39-4109-8c92-42af5d01351e"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbIrtcaCj3Wj"
   },
   "outputs": [],
   "source": [
    "# Uncommenting the following line results in a \"singular matrix\" error\n",
    "# Ninv = np.linalg.inv(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBT5VC5Nj3Wl"
   },
   "outputs": [],
   "source": [
    "N = torch.tensor([[-4, 1], [-8, 2.]]) # must use float not int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQA5g0gGj3Wm",
    "outputId": "251da4e8-92b8-45ae-e63a-aa4a66f3ba22"
   },
   "outputs": [],
   "source": [
    "torch.det(N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBIJB7tfj3Wn"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwwoY1k6j3Wn"
   },
   "source": [
    "### Generalizing Determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqjRKaCaj3Wn",
    "outputId": "4a38488f-5ab7-4959-f813-6fb3443e85ee"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uimvv39Nj3Wp",
    "outputId": "2c2a0732-0270-4bf5-e06e-956af66afb53"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Clr6afMj3Wr"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "et4bgYFDj3Wr"
   },
   "source": [
    "### Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLjGas2ij3Ws"
   },
   "source": [
    "Let's say we have a vector $v$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZvzKGRkj3Ws",
    "outputId": "180686db-9448-4d12-ca99-08e0f8fa5dcf"
   },
   "outputs": [],
   "source": [
    "v = np.array([3, 1])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UlRvHvZj3Wt"
   },
   "source": [
    "Let's plot $v$ using Hadrien Jean's handy `plotVectors` function (from [this notebook](https://github.com/hadrienj/deepLearningBook-Notes/blob/master/2.7%20Eigendecomposition/2.7%20Eigendecomposition.ipynb) under [MIT license](https://github.com/hadrienj/deepLearningBook-Notes/blob/master/LICENSE))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hl54713Rj3Wt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmyWW7Xvj3Wu"
   },
   "outputs": [],
   "source": [
    "def plotVectors(vecs, cols, alpha=1):\n",
    "    \"\"\"\n",
    "    Plot set of vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vecs : array-like\n",
    "        Coordinates of the vectors to plot. Each vectors is in an array. For\n",
    "        instance: [[1, 3], [2, 2]] can be used to plot 2 vectors.\n",
    "    cols : array-like\n",
    "        Colors of the vectors. For instance: ['red', 'blue'] will display the\n",
    "        first vector in red and the second in blue.\n",
    "    alpha : float\n",
    "        Opacity of vectors\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    fig : instance of matplotlib.figure.Figure\n",
    "        The figure of the vectors\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.axvline(x=0, color='#A9A9A9', zorder=0)\n",
    "    plt.axhline(y=0, color='#A9A9A9', zorder=0)\n",
    "\n",
    "    for i in range(len(vecs)):\n",
    "        x = np.concatenate([[0,0],vecs[i]])\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles='xy', scale_units='xy', scale=1, color=cols[i],\n",
    "                   alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uP1xgnLj3Wx",
    "outputId": "75194e3a-37ce-4185-ec47-3638ebe86448"
   },
   "outputs": [],
   "source": [
    "plotVectors([v], cols=['lightblue'])\n",
    "_ = plt.xlim(-1, 5)\n",
    "_ = plt.ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydGgh5lRj3Wy"
   },
   "source": [
    "\"Applying\" a matrix to a vector (i.e., performing matrix-vector multiplication) can linearly transform the vector, e.g, rotate it or rescale it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReW9fF-sj3Wy"
   },
   "source": [
    "The identity matrix, introduced earlier, is the exception that proves the rule: Applying an identity matrix does not transform the vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0riv3SS8j3Wz",
    "outputId": "3ae4298a-4d45-4a30-bd1f-3bba9d7a8d50"
   },
   "outputs": [],
   "source": [
    "I = np.array([[1, 0], [0, 1]])\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nc7nn6VDj3W0",
    "outputId": "d0ea9120-1072-441c-e0ca-3599862879d1"
   },
   "outputs": [],
   "source": [
    "Iv = np.dot(I, v)\n",
    "Iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXQBaq2fj3W1",
    "outputId": "80a7263f-b229-47d0-99cd-f712436e26c6"
   },
   "outputs": [],
   "source": [
    "v == Iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP81dIksj3W3",
    "outputId": "9375a9ab-bf9d-446d-f977-aa1337a13deb"
   },
   "outputs": [],
   "source": [
    "plotVectors([Iv], cols=['blue'])\n",
    "_ = plt.xlim(-1, 5)\n",
    "_ = plt.ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcdkCchSj3W4"
   },
   "source": [
    "In contrast, let's see what happens when we apply (some non-identity matrix) $A$ to the vector $v$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-EsIE7cj3W4",
    "outputId": "8bbeea02-94cf-4347-eb2a-230d585beaf3"
   },
   "outputs": [],
   "source": [
    "A = np.array([[-1, 4], [2, -2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZ0rxeKTj3W5",
    "outputId": "3190599a-7754-47d0-9916-0a6153ac148e"
   },
   "outputs": [],
   "source": [
    "Av = np.dot(A, v)\n",
    "Av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCAfNJ8hj3W7",
    "outputId": "eccd3efb-e938-4eb9-c313-ec88612f3089"
   },
   "outputs": [],
   "source": [
    "plotVectors([v, Av], ['lightblue', 'blue'])\n",
    "_ = plt.xlim(-1, 5)\n",
    "_ = plt.ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cMA5yMij3W8",
    "outputId": "e2ce5ca4-4749-40c7-b947-3e41ac7bb601"
   },
   "outputs": [],
   "source": [
    "# a second example:\n",
    "v2 = np.array([2, 1])\n",
    "plotVectors([v2, np.dot(A, v2)], ['lightgreen', 'green'])\n",
    "_ = plt.xlim(-1, 5)\n",
    "_ = plt.ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRqpCA6qj3W-"
   },
   "source": [
    "We can concatenate several vectors together into a matrix (say, $V$), where each column is a separate vector. Then, whatever linear transformations we apply to $V$ will be independently applied to each column (vector): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsRo3xPFj3W-",
    "outputId": "7ed6be60-29ec-4dcd-aadb-9c1c5809dd15"
   },
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQDdsKXNj3XA",
    "outputId": "17255afd-aa09-4f00-cc5e-45ce87cb92f0"
   },
   "outputs": [],
   "source": [
    "# recall that we need to convert array to 2D to transpose into column, e.g.:\n",
    "np.matrix(v).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zb9cSgjnj3XB"
   },
   "outputs": [],
   "source": [
    "v3 = np.array([-3, -1]) # mirror image of x over both axes\n",
    "v4 = np.array([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsdcEFXYj3XC",
    "outputId": "82d690a4-4609-4066-8cba-35d2ec7a3dc9"
   },
   "outputs": [],
   "source": [
    "V = np.concatenate((np.matrix(v).T, \n",
    "                    np.matrix(v2).T,\n",
    "                    np.matrix(v3).T,\n",
    "                    np.matrix(v4).T), \n",
    "                   axis=1)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3CSo0Hrj3XD",
    "outputId": "b568ad45-390d-40dd-ad88-e74e35f36172"
   },
   "outputs": [],
   "source": [
    "IV = np.dot(I, V)\n",
    "IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6M61JEWj3XE",
    "outputId": "2bacb4b7-accc-48a1-f966-9717fcc04343"
   },
   "outputs": [],
   "source": [
    "AV = np.dot(A, V)\n",
    "AV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGmvjr85j3XG"
   },
   "outputs": [],
   "source": [
    "# function to convert column of matrix to 1D vector: \n",
    "def vectorfy(mtrx, clmn):\n",
    "    return np.array(mtrx[:,clmn]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2eQ4w83j3XH",
    "outputId": "6a972e6d-6011-4842-ebab-c4368e1ee456"
   },
   "outputs": [],
   "source": [
    "vectorfy(V, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_o4HOgEwj3XI",
    "outputId": "9f4c5c00-997d-40a8-cca1-caa2e8377def"
   },
   "outputs": [],
   "source": [
    "vectorfy(V, 0) == v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btsivNB_j3XK",
    "outputId": "63d1db88-f0c4-414a-ed8f-67b37244fc02"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(V, 0), vectorfy(V, 1), vectorfy(V, 2), vectorfy(V, 3),\n",
    "             vectorfy(AV, 0), vectorfy(AV, 1), vectorfy(AV, 2), vectorfy(AV, 3)], \n",
    "            ['lightblue', 'lightgreen', 'lightgray', 'orange',\n",
    "             'blue', 'green', 'gray', 'red'])\n",
    "_ = plt.xlim(-4, 6)\n",
    "_ = plt.ylim(-5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bmZcXc6Xj3XL"
   },
   "source": [
    "**Return to slides here for pencil-and-paper questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4n31lIDpj3XL"
   },
   "source": [
    "Now that we can appreciate linear transformation of vectors by matrices, let's move on to working with eigenvectors and eigenvalues. \n",
    "\n",
    "An **eigenvector** (*eigen* is German for \"typical\"; we could translate *eigenvector* to \"characteristic vector\") is a special vector $v$ such that when it is transformed by some matrix (let's say $A$), the product $Av$ has the exact same direction as $v$.\n",
    "\n",
    "An **eigenvalue** is a scalar (traditionally represented as $\\lambda$) that simply scales the eigenvector $v$ such that the following equation is satisfied: \n",
    "\n",
    "$Av = \\lambda v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7zVjpW-j3XL"
   },
   "source": [
    "Easiest way to understand this is to work through an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbXJtk1Ej3XL",
    "outputId": "4fe3b949-175c-4a22-873a-7690d3e4c443"
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0t2JsM6Wj3XN"
   },
   "source": [
    "Eigenvectors and eigenvalues can be derived algebraically (e.g., with the [QR algorithm](https://en.wikipedia.org/wiki/QR_algorithm), which was independent developed in the 1950s by both [Vera Kublanovskaya](https://en.wikipedia.org/wiki/Vera_Kublanovskaya) and John Francis), however this is outside scope of today's class. We'll cheat with NumPy `eig()` method, which returns a tuple of: \n",
    "\n",
    "* a vector of eigenvalues\n",
    "* a matrix of eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYWmgM7jj3XN"
   },
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVUp_p6-j3XO"
   },
   "source": [
    "The matrix contains as many eigenvectors as there are columns of A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iHlAMa7j3XO",
    "outputId": "9a4a2b4c-401c-4587-cd11-6f60751d4ce7"
   },
   "outputs": [],
   "source": [
    "V # each column is a separate eigenvector v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBSmc2JLj3XP"
   },
   "source": [
    "With a corresponding eigenvalue for each eigenvector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYJbCydNj3XP",
    "outputId": "527f7f51-b2b5-4f0c-f840-bd5b144c2eba"
   },
   "outputs": [],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OoZPiaBMj3XR"
   },
   "source": [
    "Let's confirm that $Av = \\lambda v$ for the first eigenvector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1QZ57TJj3XR",
    "outputId": "32386f00-070a-4c6a-eb30-3d2d09c45a4b"
   },
   "outputs": [],
   "source": [
    "v = V[:,0] \n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vwkWMiIj3XV",
    "outputId": "1b274e96-01d7-4104-fbe7-f91ae5826fe9"
   },
   "outputs": [],
   "source": [
    "lambduh = lambdas[0] # note that \"lambda\" is reserved term in Python\n",
    "lambduh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Leh9n8QBj3XW",
    "outputId": "3165479f-bb06-422d-bbcf-5e8b4b35e66e"
   },
   "outputs": [],
   "source": [
    "Av = np.dot(A, v)\n",
    "Av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PROIJU30j3XX",
    "outputId": "833d6e53-6d1b-4759-f5cf-3e28af96ff30"
   },
   "outputs": [],
   "source": [
    "lambduh * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0bT3vjoQj3XY",
    "outputId": "dc53ddfc-5703-407e-ec3a-e146d779841c"
   },
   "outputs": [],
   "source": [
    "plotVectors([Av, v], ['blue', 'lightblue'])\n",
    "_ = plt.xlim(-1, 2)\n",
    "_ = plt.ylim(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKQI4691j3XZ"
   },
   "source": [
    "And again for the second eigenvector of A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riOJuqz3j3XZ",
    "outputId": "992b8b02-ef09-4de5-db15-bffcedc722a2"
   },
   "outputs": [],
   "source": [
    "v2 = V[:,1]\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QveeHYhDj3Xa",
    "outputId": "9985e974-655f-4acb-dc38-e5fac398ae7b"
   },
   "outputs": [],
   "source": [
    "lambda2 = lambdas[1]\n",
    "lambda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDk1VoVIj3Xb",
    "outputId": "ccc3fa42-455a-4491-f75e-86d6f9c464f6"
   },
   "outputs": [],
   "source": [
    "Av2 = np.dot(A, v2)\n",
    "Av2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smlYxxgpj3Xc",
    "outputId": "e36bef99-5e6a-42a9-8669-910e636676df"
   },
   "outputs": [],
   "source": [
    "lambda2 * v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IigKHp0j3Xd",
    "outputId": "c2dc34fb-5384-47de-a325-4e053417563c"
   },
   "outputs": [],
   "source": [
    "plotVectors([Av, v, Av2, v2], \n",
    "            ['blue', 'lightblue', 'green', 'lightgreen'])\n",
    "_ = plt.xlim(-1, 4)\n",
    "_ = plt.ylim(-3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VF9uLWjOj3Xe"
   },
   "source": [
    "Using the PyTorch `eig()` method, we can do exactly the same: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcJa6w0mj3Xe",
    "outputId": "8980d896-85e5-4081-d373-fc61e3cba9d8"
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WvCqoRij3Xf",
    "outputId": "309a5053-1af0-4859-9dd6-8101dc78aaff"
   },
   "outputs": [],
   "source": [
    "A_p = torch.tensor([[-1, 4], [2, -2.]]) # must be float for PyTorch eig()\n",
    "A_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27FbfPXGj3Xg",
    "outputId": "df1ccbc4-31a0-4440-e006-b08a5c4f5daa"
   },
   "outputs": [],
   "source": [
    "eigens = torch.eig(A_p, eigenvectors=True) \n",
    "eigens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gz2_l7ebj3Xh",
    "outputId": "3f82b260-845e-4208-fe69-405a73f4fa09"
   },
   "outputs": [],
   "source": [
    "v_p = eigens.eigenvectors[:,0]\n",
    "v_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrYaxNCRj3Xj",
    "outputId": "565234c5-973f-4992-8281-e2125d751a70"
   },
   "outputs": [],
   "source": [
    "lambda_p = eigens.eigenvalues[0][0]\n",
    "lambda_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUq1UGH7j3Xl",
    "outputId": "0a1ab88b-c83c-4938-df90-d25c13f3336f"
   },
   "outputs": [],
   "source": [
    "Av_p = torch.matmul(A_p, v_p)\n",
    "Av_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "co1VNLIej3Xn",
    "outputId": "7a6ab193-43d9-405d-f55f-6b70a05da0ae"
   },
   "outputs": [],
   "source": [
    "lambda_p * v_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1b47vG92j3Xo",
    "outputId": "8c7f2adb-b54e-4adf-f928-f9ca2646874e"
   },
   "outputs": [],
   "source": [
    "v2_p = eigens.eigenvectors[:,1]\n",
    "v2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-evpW17j3Xp",
    "outputId": "7e7c3cc5-ebfa-4c00-cf82-3c2623758be3"
   },
   "outputs": [],
   "source": [
    "lambda2_p = eigens.eigenvalues[1][0]\n",
    "lambda2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2d5gjh2sj3Xq",
    "outputId": "56ed7ce8-aaf4-4b9e-d9fa-ec5f8f6d31c5"
   },
   "outputs": [],
   "source": [
    "Av2_p = torch.matmul(A_p, v2_p)\n",
    "Av2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-ki3i8dj3Xr",
    "outputId": "1d1b5f93-370f-405e-fac5-eba55e9267d9"
   },
   "outputs": [],
   "source": [
    "lambda2_p * v2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2p8yb_Zj3Xs",
    "outputId": "fca8be0a-eb8c-4f1b-bf3e-12883a5cdd09"
   },
   "outputs": [],
   "source": [
    "plotVectors([Av_p.numpy(), v_p.numpy(), Av2_p.numpy(), v2_p.numpy()], \n",
    "            ['blue', 'lightblue', 'green', 'lightgreen'])\n",
    "_ = plt.xlim(-1, 4)\n",
    "_ = plt.ylim(-3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-HqwyESj3Xt"
   },
   "source": [
    "### Eigenvectors in >2 Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M01JPwToj3Xt"
   },
   "source": [
    "While plotting gets trickier in higher-dimensional spaces, we can nevertheless find and use eigenvectors with more than two dimensions. Here's a 3D example (there are three dimensions handled over three rows): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWsBDEMgj3Xt",
    "outputId": "da9e86f2-da5f-4586-cb43-5a4a997492db"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-uUMyRFj3Xv"
   },
   "outputs": [],
   "source": [
    "lambdas_X, V_X = np.linalg.eig(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "virh7GVFj3Xw",
    "outputId": "9de3d28c-610b-4b8a-e913-8cd84f2383ec"
   },
   "outputs": [],
   "source": [
    "V_X # one eigenvector per column of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yHkmEd0j3Xw",
    "outputId": "f2c36081-ca90-451c-d6dd-b1bf4416abc0"
   },
   "outputs": [],
   "source": [
    "lambdas_X # a corresponding eigenvalue for each eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qp3qPeUxj3Xy"
   },
   "source": [
    "Confirm $Xv = \\lambda v$ for an example vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUEfbThhj3Xy",
    "outputId": "d28db68f-5855-4ed1-bf62-b1972ed93461"
   },
   "outputs": [],
   "source": [
    "v_X = V_X[:,0] \n",
    "v_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhnF5asDj3X0",
    "outputId": "86a568fe-27d1-456b-bcc7-aa5fff4e8c84"
   },
   "outputs": [],
   "source": [
    "lambda_X = lambdas_X[0] \n",
    "lambda_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3bA6vRzj3X1",
    "outputId": "be53cc8d-00a2-4d6c-dd34-9dcc9b2906fd"
   },
   "outputs": [],
   "source": [
    "np.dot(X, v_X) # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfN3hk0Gj3X2",
    "outputId": "249e8bca-d69e-4202-ab61-1d3232629e52"
   },
   "outputs": [],
   "source": [
    "lambda_X * v_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcjTZv24j3X3"
   },
   "source": [
    "**Exercises**:\n",
    "\n",
    "1. Use PyTorch to confirm $Xv = \\lambda v$ for the first eigenvector of $X$.\n",
    "2. Confirm $Xv = \\lambda v$ for the remaining eigenvectors of $X$ (you can use NumPy or PyTorch, whichever you prefer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5z5AdeHKj3X4"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOdacj28j3X4"
   },
   "source": [
    "### Determinants Revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WK2By3pj3X4",
    "outputId": "d46e4bac-2cda-4977-d76b-5eb4dd98d83b"
   },
   "outputs": [],
   "source": [
    "X = np.array([[4, 2], [-5, -3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwF2s-4Gj3X5",
    "outputId": "3e83eecd-7e85-4f3b-ae1d-cc2bad11ea4f"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0uEEY2qj3X6",
    "outputId": "46b324e0-bd95-4c8b-f91b-2ea188b0e0a4"
   },
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(X)\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41P8dP9Gj3X8",
    "outputId": "a54bd6e4-055c-4999-a78b-325ede395597"
   },
   "outputs": [],
   "source": [
    "np.product(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7Bleu07j3X-",
    "outputId": "1a190bab-cc1c-4961-9dee-b56a3479ea44"
   },
   "outputs": [],
   "source": [
    "np.abs(np.product(lambdas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpDJ0y-Cj3X-"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMPe8LOXj3X_",
    "outputId": "d3f2f157-85f7-49e0-e084-c8329901c297"
   },
   "outputs": [],
   "source": [
    "B = np.array([[1, 0], [0, 1]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlhnOiNzj3YA",
    "outputId": "aeef875f-c003-48de-e140-d51bec5bc5f8"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1)],\n",
    "            ['lightblue', 'lightgreen'])\n",
    "_ = plt.xlim(-1, 3)\n",
    "_ = plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjpem_6Ij3YB",
    "outputId": "5357a768-5ce5-4506-e7ef-2fcb8eff821b"
   },
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BhgWTvaj3YC",
    "outputId": "b5977945-7ed4-4301-a884-ebc5d179198a"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3XSySPaj3YE",
    "outputId": "99134bfc-b3d2-4f17-80eb-6256fc8d0c08"
   },
   "outputs": [],
   "source": [
    "NB = np.dot(N, B)\n",
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLiyz0nxj3YF",
    "outputId": "6e0f19af-b700-4a5d-d9ef-f83e1d15bc93"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(NB, 0), vectorfy(NB, 1)],\n",
    "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
    "_ = plt.xlim(-6, 6)\n",
    "_ = plt.ylim(-9, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqEkY-8lj3YH",
    "outputId": "75b1aa94-044e-4950-a7e2-89cf6fa15414"
   },
   "outputs": [],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwmKA0wLj3YI",
    "outputId": "b7ec8bd6-8bfa-48f6-c2b5-c6109c7546d1"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xaIq_dUKj3YJ",
    "outputId": "0cf90877-a9e7-4863-dc6a-07d96b314efb"
   },
   "outputs": [],
   "source": [
    "IB = np.dot(I, B)\n",
    "IB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8y6svzaLj3YK",
    "outputId": "a4f1d555-790a-445e-eff8-7027f658143b"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(IB, 0), vectorfy(IB, 1)],\n",
    "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
    "_ = plt.xlim(-1, 3)\n",
    "_ = plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xj4bnqVcj3YL",
    "outputId": "41795c0a-8a56-4bef-9097-1788cd5d906f"
   },
   "outputs": [],
   "source": [
    "J = np.array([[-0.5, 0], [0, 2]])\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2ODTOpAj3YM",
    "outputId": "5b6498e0-9bef-45eb-fb30-7869eace08ee"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kHJ7Q2Ij3YN",
    "outputId": "12d2b176-944d-4a1e-c140-b489ea91b5d2"
   },
   "outputs": [],
   "source": [
    "np.abs(np.linalg.det(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABciINQwj3YO",
    "outputId": "e3c94eca-4cf9-4e78-cf0c-8adabc234e97"
   },
   "outputs": [],
   "source": [
    "JB = np.dot(J, B)\n",
    "JB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nWa22ZNj3YO",
    "outputId": "14671995-3dd7-4ba6-815d-88cba03e8302"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(JB, 0), vectorfy(JB, 1)],\n",
    "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
    "_ = plt.xlim(-1, 3)\n",
    "_ = plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-OI7xBWj3YQ"
   },
   "outputs": [],
   "source": [
    "doubleI = I*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKoTu9sbj3YR",
    "outputId": "b4de617b-60c9-43ff-9084-d105fb6bc62e"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(doubleI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTb0o2Ydj3YS",
    "outputId": "847204c0-ed6c-430b-f8fc-20d6a3c6e74f"
   },
   "outputs": [],
   "source": [
    "doubleIB = np.dot(doubleI, B)\n",
    "doubleIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3J2ou_zSj3YT",
    "outputId": "d8646e60-d161-4963-e2f9-ef26726853db"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(doubleIB, 0), vectorfy(doubleIB, 1)],\n",
    "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
    "_ = plt.xlim(-1, 3)\n",
    "_ = plt.ylim(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPCdmKo7j3YU",
    "outputId": "398abaeb-8b73-4266-c05f-4d20fc225c68"
   },
   "outputs": [],
   "source": [
    "# returning to the matrix X...\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5NtD3VPj3YV",
    "outputId": "002d0e31-fc44-433c-df66-29ad76ae09ce"
   },
   "outputs": [],
   "source": [
    "# with its absolute det(X) of 2: \n",
    "np.abs(np.linalg.det(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wulX_Zihj3YY",
    "outputId": "903990ac-69ca-4c00-d713-c89811ae8235"
   },
   "outputs": [],
   "source": [
    "XB = np.dot(X, B)\n",
    "XB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4o2NBMt1j3YZ",
    "outputId": "98f7aa9e-f986-4fb6-d695-56aba2ab29be"
   },
   "outputs": [],
   "source": [
    "plotVectors([vectorfy(B, 0), vectorfy(B, 1), vectorfy(XB, 0), vectorfy(XB, 1)],\n",
    "            ['lightblue', 'lightgreen', 'blue', 'green'])\n",
    "_ = plt.xlim(-1, 5)\n",
    "_ = plt.ylim(-6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av0R8fddj3Yb"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXNajp3Ej3Yb"
   },
   "source": [
    "### Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQt403xbj3Yb"
   },
   "source": [
    "The **eigendecomposition** of some matrix $A$ is \n",
    "\n",
    "$A = V \\Lambda V^{-1}$\n",
    "\n",
    "Where: \n",
    "\n",
    "* As in examples above, $V$ is the concatenation of all the eigenvectors of $A$\n",
    "* $\\Lambda$ (upper-case $\\lambda$) is the diagonal matrix diag($\\lambda$). Note that the convention is to arrange the lambda values in descending order; as a result, the first eigenvector (and its associated eigenvector) may be a primary characteristic of the matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7LmR3YGj3Yb",
    "outputId": "4b5c460a-b49c-4241-c544-0f62f0ea33d2"
   },
   "outputs": [],
   "source": [
    "# The matrix X from the inversion example much earlier has \n",
    "# nice, clean integer eigenvalues, so let's work with it here: \n",
    "A = X\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37zeBrqhj3Yc"
   },
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7LtIIMJj3Yd",
    "outputId": "7d9608df-6e8f-42e0-8004-462eb48267f2"
   },
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1uuRwcdj3Ye",
    "outputId": "8383e3f8-ef3b-421b-8347-e26a1f0db56b"
   },
   "outputs": [],
   "source": [
    "Vinv = np.linalg.inv(V)\n",
    "Vinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_InHRuS1j3Yf",
    "outputId": "0191817d-bf9b-455c-deec-1c4d068065b8"
   },
   "outputs": [],
   "source": [
    "Lambda = np.diag(lambdas)\n",
    "Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSBnzTBZj3Yg"
   },
   "source": [
    "Confirm that $A = V \\Lambda V^{-1}$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG1E3yLYj3Yg",
    "outputId": "59e6239c-e5ee-453f-8491-6ca89ffcc9ff"
   },
   "outputs": [],
   "source": [
    "np.dot(V, np.dot(Lambda, Vinv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTmKZk8fj3Yh"
   },
   "source": [
    "Eigendecomposition is not possible with all matrices. And in some cases where it is possible, the eigendecomposition involves complex numbers instead of straightforward real numbers. \n",
    "\n",
    "In machine learning, however, we are typically working with real symmetric matrices, which can be conveniently and efficiently decomposed into real-only eigenvectors and real-only eigenvalues. If $A$ is a real symmetric matrix then...\n",
    "\n",
    "$A = Q \\Lambda Q^T$\n",
    "\n",
    "...where $Q$ is analogous to $V$ from the previous equation except that it's special because it's an orthogonal matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpZLd9Ozj3Yh",
    "outputId": "ad679f93-087a-4021-caf5-9bf80eac47c4"
   },
   "outputs": [],
   "source": [
    "A = np.array([[2, 1], [1, 2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJOgExEZj3Yj"
   },
   "outputs": [],
   "source": [
    "lambdas, Q = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qouDzN5j3Yk",
    "outputId": "19d23366-93e8-4e84-a74d-040bb382748d"
   },
   "outputs": [],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZFyXQzkj3Yl",
    "outputId": "782e731a-d0f8-404e-9226-f01bf2c9d7ab"
   },
   "outputs": [],
   "source": [
    "Lambda = np.diag(lambdas)\n",
    "Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLXaGoVBj3Yl",
    "outputId": "86a3fdd6-05aa-41b7-f832-1b7c65806ee3"
   },
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eq_1nssj3Ym"
   },
   "source": [
    "Recalling that $Q^TQ = QQ^T = I$, can demonstrate that $Q$ is an orthogonal matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcavBhdEj3Ym",
    "outputId": "590b2ba2-418e-40aa-eb7d-5c0550d74988"
   },
   "outputs": [],
   "source": [
    "np.dot(Q.T, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xup113b8j3Yo",
    "outputId": "df2493e1-e0a1-4499-8234-3feacc1ff9e3"
   },
   "outputs": [],
   "source": [
    "np.dot(Q, Q.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnOfuIf7j3Yo"
   },
   "source": [
    "Let's confirm $A = Q \\Lambda Q^T$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4DukMWJj3Yo",
    "outputId": "eafffd5d-0ffb-4636-c225-5fb9c15d09f8"
   },
   "outputs": [],
   "source": [
    "np.dot(Q, np.dot(Lambda, Q.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdJaTKnsj3Yp"
   },
   "source": [
    "**Exercises**:\n",
    "\n",
    "1. Use PyTorch to decompose the matrix $P$ (below) into its components $V$, $\\Lambda$, and $V^{-1}$. Confirm that $P = V \\Lambda V^{-1}$.\n",
    "2. Use PyTorch to decompose the symmetric matrix $S$ (below) into its components $Q$, $\\Lambda$, and $Q^T$. Confirm that $S = Q \\Lambda Q^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RVUCVlvj3Yp",
    "outputId": "7abc66ce-1fa3-4c1b-cea9-1da3d0f8ade6"
   },
   "outputs": [],
   "source": [
    "P = torch.tensor([[25, 2, -5], [3, -2, 1], [5, 7, 4.]])\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjKZ_AWLj3Yq",
    "outputId": "b9ee6619-60b4-4fb5-c88b-0fe313039635"
   },
   "outputs": [],
   "source": [
    "S = torch.tensor([[25, 2, -5], [2, -2, 1], [-5, 1, 4.]])\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OFq3uGaj3Yq"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKam0tJOj3Yr"
   },
   "source": [
    "## Segment 3: Matrix Operations for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-wbn7omj3Yr"
   },
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2SHytttj3Yr"
   },
   "source": [
    "As on slides, SVD of matrix $A$ is: \n",
    "\n",
    "$A = UDV^T$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $U$ is an orthogonal $m \\times m$ matrix; its columns are the **left-singular vectors** of $A$.\n",
    "* $V$ is an orthogonal $n \\times n$ matrix; its columns are the **right-singular vectors** of $A$.\n",
    "* $D$ is a diagonal $m \\times n$ matrix; elements along its diagonal are the **singular values** of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7hR4Htdj3Yr",
    "outputId": "d0399dd8-fde2-4c20-8015-e825117c76a9"
   },
   "outputs": [],
   "source": [
    "A = np.array([[-1, 2], [3, -2], [5, 7]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihj2XfMQj3Ys"
   },
   "outputs": [],
   "source": [
    "U, d, VT = np.linalg.svd(A) # V is already transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUfP2aaTj3Yv",
    "outputId": "37f47eca-2391-46b3-993f-923dc20eb034"
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_Fkoarvj3Yw",
    "outputId": "ed097007-023b-43cb-9e9a-f4d7bc925466"
   },
   "outputs": [],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNSRDcfsj3Yx",
    "outputId": "5e0565b6-c57a-4d08-ec2e-da33d7cc956f"
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lbxh2rYoj3Yy",
    "outputId": "a62efd6d-c1d3-463b-8c7b-4621bf170349"
   },
   "outputs": [],
   "source": [
    "np.diag(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V47I3B87j3Y0",
    "outputId": "6e0dbbd4-f080-4f50-f56a-f1fbc95248a1"
   },
   "outputs": [],
   "source": [
    "D = np.concatenate((np.diag(d), [[0, 0]]), axis=0)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9euCs5vvj3Y2",
    "outputId": "75c652fe-01bb-45a1-d9a6-89e91bf83e54"
   },
   "outputs": [],
   "source": [
    "np.dot(U, np.dot(D, VT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-WCBOzKj3Y3"
   },
   "source": [
    "SVD and eigendecomposition are closely related to each other: \n",
    "\n",
    "* Left-singular vectors of $A$ = eigenvectors of $AA^T$.\n",
    "* Right-singular vectors of $A$ = eigenvectors of $A^TA$.\n",
    "* Non-zero singular values of $A$ = square roots of eigenvectors of $AA^T$ = square roots of eigenvectors of $A^TA$\n",
    "\n",
    "**Exercise**: Using the matrix `P` from the preceding PyTorch exercises, demonstrate that these three SVD-eigendecomposition equations are true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWEOMqUUj3Y3"
   },
   "source": [
    "### Image Compression via SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmRvLo_Tj3Y3"
   },
   "source": [
    "The section features code adapted from [Frank Cleary's](https://gist.github.com/frankcleary/4d2bd178708503b556b0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luD8Y98Vj3Y3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thPmYUx4j3Y4"
   },
   "source": [
    "Fetch photo of Oboe, a terrier, with the book *Deep Learning Illustrated*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPUItNUVj3Y4",
    "outputId": "cb38ee6c-a746-4318-c8a6-f6fed7d9b163"
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/jonkrohn/DLTFpT/master/notebooks/oboe-with-book.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lx_Frl6j3Y6",
    "outputId": "a9b87d11-2d9a-4d28-db5c-512985470336"
   },
   "outputs": [],
   "source": [
    "img = Image.open('oboe-with-book.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYmg1Fa8j3Y6"
   },
   "source": [
    "Convert image to grayscale so that we don't have to deal with the complexity of multiple color channels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uki3S6w0j3Y7",
    "outputId": "97a2a67e-bc40-4de2-f162-9777a4e5c8b3"
   },
   "outputs": [],
   "source": [
    "imggray = img.convert('LA')\n",
    "plt.imshow(imggray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVwgrA0Jj3Y9"
   },
   "source": [
    "Convert data into numpy matrix, which doesn't impact image data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHijyFgUj3Y9",
    "outputId": "6a6edcbf-aed9-461c-95ab-f9353287c330"
   },
   "outputs": [],
   "source": [
    "imgmat = np.array(list(imggray.getdata(band=0)), float)\n",
    "imgmat.shape = (imggray.size[1], imggray.size[0])\n",
    "imgmat = np.matrix(imgmat)\n",
    "plt.imshow(imgmat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8VCD3lyj3Y-"
   },
   "source": [
    "Calculate SVD of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbBLn2Csj3Y-"
   },
   "outputs": [],
   "source": [
    "U, sigma, V = np.linalg.svd(imgmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApybkCdLj3Y-"
   },
   "source": [
    "As eigenvalues are arranged in descending order in diag($\\lambda$) so to are singular values, by convention, arranged in descending order in $D$ (or, in this code, diag($\\sigma$)). Thus, the first left-singular vector of $U$ and first right-singular vector of $V$ may represent the most prominent feature of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZTwlhGxj3Y_",
    "outputId": "1560da9a-70a4-4529-ff7d-f6df772e608e"
   },
   "outputs": [],
   "source": [
    "reconstimg = np.matrix(U[:, :1]) * np.diag(sigma[:1]) * np.matrix(V[:1, :])\n",
    "plt.imshow(reconstimg, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p2cEqIoj3Y_"
   },
   "source": [
    "Additional singular vectors improve the image quality: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5-6LEbij3ZA",
    "outputId": "41a72677-6f00-46b7-d440-7c18546bfee3"
   },
   "outputs": [],
   "source": [
    "for i in [2, 4, 8, 16, 32, 64]:\n",
    "    reconstimg = np.matrix(U[:, :i]) * np.diag(sigma[:i]) * np.matrix(V[:i, :])\n",
    "    plt.imshow(reconstimg, cmap='gray')\n",
    "    title = \"n = %s\" % i\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjfUJ4wNj3ZA"
   },
   "source": [
    "With 64 singular vectors, the image is reconstructed quite well, however the data footprint is much smaller than the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXQy4TzCj3ZB",
    "outputId": "28b856f8-c3e0-4da1-ee3d-7dbf12fc92de"
   },
   "outputs": [],
   "source": [
    "imgmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwdA6taLj3ZD",
    "outputId": "fd993012-1e41-4817-9037-ee5867b4ed15"
   },
   "outputs": [],
   "source": [
    "(64*4032 + 64 + 64*3024)/(4032*3024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HdtL8p7j3ZD"
   },
   "source": [
    "Specifically, the image represented as 64 singular vectors is 3.7% of the size of the original!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBQnc4uGj3ZE"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEnTYLbBj3ZE"
   },
   "source": [
    "### The Moore-Penrose Pseudoinverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4_MX4D5j3ZE"
   },
   "source": [
    "Let's calculate the pseudoinverse $A^+$ of some matrix $A$ using the formula from the slides: \n",
    "\n",
    "$A^+ = VD^+U^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbbiRcmzj3ZE",
    "outputId": "ed4921a7-8360-46b3-e928-5d554b2353b9"
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFNYVdZ4j3ZF"
   },
   "source": [
    "As shown earlier, the NumPy SVD method returns $U$, $d$, and $V^T$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6NjgNbjj3ZF"
   },
   "outputs": [],
   "source": [
    "U, d, VT = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sROQTAzj3ZG",
    "outputId": "eb770b9f-7790-4749-ec31-f6fbff959c11"
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drDSW-vkj3ZG",
    "outputId": "392d0405-73d8-4b22-90bd-48596c41ccfd"
   },
   "outputs": [],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sr3jIv4Jj3ZH",
    "outputId": "b4affc7f-02c0-42e9-ce4f-08b3b9029b67"
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yalmt19j3ZI"
   },
   "source": [
    "To create $D^+$, we first invert the non-zero values of $d$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEvRLwQfj3ZI",
    "outputId": "12e4dd08-d35d-4949-93c9-c766d91c23fd"
   },
   "outputs": [],
   "source": [
    "D = np.diag(d)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6O2LADtLj3ZJ",
    "outputId": "d90103ed-14cc-4d0a-de03-c9f433904535"
   },
   "outputs": [],
   "source": [
    "1/8.669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1ZbYtmIj3ZJ",
    "outputId": "5da3ca1f-3392-4112-aa3b-718d634987b0"
   },
   "outputs": [],
   "source": [
    "1/4.104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yO1tNES9j3ZK"
   },
   "source": [
    "...and then we would take the tranpose of the resulting matrix.\n",
    "\n",
    "Because $D$ is a diagonal matrix, this can, however, be done in a single step by inverting $D$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0sjcP3Ej3ZK",
    "outputId": "237289cf-5784-4d92-da00-e8489a7be541"
   },
   "outputs": [],
   "source": [
    "Dinv = np.linalg.inv(D)\n",
    "Dinv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXJnvna-j3ZM"
   },
   "source": [
    "The final $D^+$ matrix needs to have a shape that can undergo matrix multiplication in the $A^+ = VD^+U^T$ equation. These dimensions can be obtained from $A$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yK1PadPFj3ZM",
    "outputId": "01fc6273-3895-4e20-81be-bbcec80b783e"
   },
   "outputs": [],
   "source": [
    "A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5bfwPDSj3ZM",
    "outputId": "fb6e523d-8dc3-4b4f-b355-882e710861da"
   },
   "outputs": [],
   "source": [
    "A.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ghxh-1P4j3ZN",
    "outputId": "d6023ea0-0525-475d-e7e7-39018582b66e"
   },
   "outputs": [],
   "source": [
    "Dplus = np.zeros((3, 2)).T\n",
    "Dplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTfh42jEj3ZO",
    "outputId": "6f847066-ba6b-4f2a-f106-9f114066fd46"
   },
   "outputs": [],
   "source": [
    "Dplus[:2, :2] = Dinv\n",
    "Dplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Xt4NYHuj3ZO"
   },
   "source": [
    "Now we have everything we need to calculate $A^+$ with $VD^+U^T$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtWN_wnij3ZO",
    "outputId": "46b2627b-ebd8-4f12-d554-e2a0d49ce031"
   },
   "outputs": [],
   "source": [
    "np.dot(VT.T, np.dot(Dplus, U.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3syT7-hCj3ZP"
   },
   "source": [
    "Working out this derivation is helpful for understanding how Moore-Penrose pseudoinverses work, but unsurprisingly NumPy is loaded with an existing method `pinv()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fh0nDMeLj3ZP",
    "outputId": "ea3f09c0-2046-42ea-ae93-121ab9e7e585"
   },
   "outputs": [],
   "source": [
    "np.linalg.pinv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNrIfpAij3ZS"
   },
   "source": [
    "**Exercise** \n",
    "\n",
    "Use the `torch.svd()` method to calculate the pseudoinverse of `A_p`, confirming that your result matches the output of `torch.pinverse(A_p)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2635vlEj3ZS",
    "outputId": "702b613f-1748-4af8-b515-6c9e887ce8b2"
   },
   "outputs": [],
   "source": [
    "A_p = torch.tensor([[-1, 2], [3, -2], [5, 7.]])\n",
    "A_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW4SsUOlj3ZT",
    "outputId": "86d514f8-1fac-4ed1-b6ec-00c167066667"
   },
   "outputs": [],
   "source": [
    "torch.pinverse(A_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KlXBgI3Nj3ZT"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMnIqjpfj3ZT"
   },
   "source": [
    "For regression problems, we typically have many more cases ($n$, or rows of $X$) than features to predict ($m$, or columns of $X$). Let's solve a miniature example of such an overdetermined situation. \n",
    "\n",
    "We have eight data points ($n$ = 8): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ft4PXaTj3ZU"
   },
   "outputs": [],
   "source": [
    "x1 = [0, 1, 2, 3, 4, 5, 6, 7.]\n",
    "y = [-.82, -.94, -.12, .26, .39, .64, 1.02, 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiMAISFBj3ZW",
    "outputId": "f4739a01-fe06-432a-ede9-0ee8eadba0ca"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.scatter(x1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWZUFeqzj3ZX"
   },
   "source": [
    "Although it appears there is only one predictor ($x_1$), we need a second one (let's call it $x_0$) in order to allow for a $y$-intercept (therefore, $m$ = 2). Without this second variable, the line we fit to the plot would need to pass through the origin (0, 0). The $y$-intercept is constant across all the points so we can set it equal to `1` across the board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpAIoxydj3ZX",
    "outputId": "23fba07b-daf5-4e46-da2f-e2018dbf11c8"
   },
   "outputs": [],
   "source": [
    "x0 = np.ones(8)\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bkwC8Wnj3ZY"
   },
   "source": [
    "Concatenate $x_0$ and $x_1$ into a matrix $X$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x56TMNFMj3ZY",
    "outputId": "f5d261ff-1fd8-449f-f780-81de2ac91abe"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((np.matrix(x0).T, np.matrix(x1).T), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7TomkyCj3ZY"
   },
   "source": [
    "From the slides, we know that we can compute the weights $w$ using the pseudoinverse of $w = X^+y$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRYhw-N0j3ZZ",
    "outputId": "b6fd116b-99d7-475d-f951-9408f4b41b2f"
   },
   "outputs": [],
   "source": [
    "w = np.dot(np.linalg.pinv(X), y)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2SoGsRNj3ZZ"
   },
   "source": [
    "The first weight corresponds to the $y$-intercept of the line, which is typically denoted as $b$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLvuVmBGj3ZZ",
    "outputId": "12b69842-6e34-4e93-b0ac-decb8271efe6"
   },
   "outputs": [],
   "source": [
    "b = np.asarray(w).reshape(-1)[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96XCC8Z-j3Za"
   },
   "source": [
    "While the second weight corresponds to the slope of the line, which is typically denoted as $m$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHTNUSJCj3Za",
    "outputId": "94d24206-e622-4d78-f037-063e9122831d"
   },
   "outputs": [],
   "source": [
    "m = np.asarray(w).reshape(-1)[1]\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvGCTZRqj3Zc"
   },
   "source": [
    "With the weights we can plot the line to confirm it fits the points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9SAiUyej3Zc",
    "outputId": "e648a5c1-25d1-410d-d801-c61a2c15e944"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1, y)\n",
    "\n",
    "x_min, x_max = ax.get_xlim()\n",
    "y_min, y_max = b, b + m*(x_max-x_min)\n",
    "\n",
    "ax.plot([x_min, x_max], [y_min, y_max])\n",
    "_ = ax.set_xlim([x_min, x_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJnSV2afj3Zd"
   },
   "source": [
    "### The Trace Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dq9uqorvj3Zd"
   },
   "source": [
    "Denoted as Tr($A$). Simply the sum of the diagonal elements of a matrix: $$\\sum_i A_{i,i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOdkry9ij3Zd",
    "outputId": "ac2b9194-6212-4053-ecef-54d342b6bfa9"
   },
   "outputs": [],
   "source": [
    "A = np.array([[25, 2], [5, 4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwh8-KTNj3Ze",
    "outputId": "b146e756-11e4-47b4-e859-b8cdc78b9da8"
   },
   "outputs": [],
   "source": [
    "25 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LxzUu37j3Zf",
    "outputId": "0dcb4d75-a641-44af-aba2-15f4c94a5a2c"
   },
   "outputs": [],
   "source": [
    "np.trace(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUeQKrYMj3Zg"
   },
   "source": [
    "The trace operator has a number of useful properties that come in handy while rearranging linear algebra equations, e.g.:\n",
    "\n",
    "* Tr($A$) = Tr($A^T$)\n",
    "* Assuming the matrix shapes line up: Tr(ABC) = Tr(CAB) = Tr(BCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuKYTjskj3Zg"
   },
   "source": [
    "In particular, the trace operator can provide a convenient way to calculate a matrix's Frobenius norm: $$||A||_F = \\sqrt{\\mathrm{Tr}(AA^\\mathrm{T})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcqTZnimj3Zg"
   },
   "source": [
    "**Exercise**\n",
    "\n",
    "Using the matrix `A_p`: \n",
    "\n",
    "1. Identify the PyTorch trace method and the trace of the matrix.\n",
    "2. Further, use the PyTorch Frobenius norm method (for the left-hand side of the equation) and the trace method (for the right-hand side of the equation) to demonstrate that $||A||_F = \\sqrt{\\mathrm{Tr}(AA^\\mathrm{T})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQhYWOFvj3Zg",
    "outputId": "bc8c70ae-d1f9-4e7c-ee18-a6112c8b8096"
   },
   "outputs": [],
   "source": [
    "A_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXuZgAUgj3Zh"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rQOXPyaj3Zh"
   },
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3_Etgo4j3Zh"
   },
   "source": [
    "This PCA example code is adapted from [here](https://jupyter.brynmawr.edu/services/public/dblank/CS371%20Cognitive%20Science/2016-Fall/PCA.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubl3WdRWj3Zh"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE2yvfEbj3Zi",
    "outputId": "7b6d1699-db20-4877-b648-1c2c10d2d0ce"
   },
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fa9fcMl2j3Zi",
    "outputId": "365fbdc9-b667-4def-85c6-d361b6038fdc"
   },
   "outputs": [],
   "source": [
    "iris.get(\"feature_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8O9xwrOLj3Zj",
    "outputId": "893e01f9-2886-4e18-f312-b5d393b49d1a"
   },
   "outputs": [],
   "source": [
    "iris.data[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoodmvRsj3Zj"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcJwICbtj3Zk"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNb6txoIj3Zk"
   },
   "outputs": [],
   "source": [
    "X = pca.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plS7skQGj3Zl",
    "outputId": "bb83578c-2310-4c32-edaa-6728d4dd063d"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC_j-7Xyj3Zl",
    "outputId": "c4c4f893-7c7c-4405-ab00-6d1698ed7863"
   },
   "outputs": [],
   "source": [
    "X[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_aNxFn5j3Zm",
    "outputId": "a26eaac4-92af-4cc4-a419-dc49e255a01b"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTck5c93j3Zm",
    "outputId": "c6f22246-3117-4be9-dd5c-ac0f53c1851a"
   },
   "outputs": [],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzGhB6NTj3Zn",
    "outputId": "7f1b1fec-b7f6-4779-adf6-331765856e1f"
   },
   "outputs": [],
   "source": [
    "iris.target[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQ8oRWsWj3Zn",
    "outputId": "26174c04-7ae5-4763-f958-fa111b20ad50"
   },
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(iris.target, return_counts=True)\n",
    "np.asarray((unique_elements, counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAIoVTYWj3Zo",
    "outputId": "438276eb-4a39-41dc-8733-8bad0a51f9d1"
   },
   "outputs": [],
   "source": [
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlZX_2vQj3Zo",
    "outputId": "c80aad27-9433-4662-e836-89f2f4b28e39"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1Y8YA2oj3Zp"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i9d2Li1j3Zp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "1-intro-to-linear-algebra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
