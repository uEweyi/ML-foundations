{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/6-statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTOLgsbN69-P"
   },
   "source": [
    "# Intro to Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yqUB9FTRAxd-"
   },
   "source": [
    "This class, *Intro to Statistics*, builds on probability theory to enable us to quantify our confidence about how distributions of data are related to one another. \n",
    "\n",
    "Through the measured exposition of theory paired with interactive examples, you’ll develop a working understanding of all of the essential statistical tests for assessing whether data are correlated with each other or sampled from different populations -- tests which frequently come in handy for critically evaluating the inputs and outputs of machine learning algorithms. You’ll also learn how to use regression to make predictions about the future based on training data. \n",
    "\n",
    "The content covered in this class builds on the content of other classes in the *Machine Learning Foundations* series (linear algebra, calculus, and probability theory) and is itself foundational for the *Optimization* class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4tBvI88BheF"
   },
   "source": [
    "Over the course of studying this topic, you'll: \n",
    "\n",
    "* Develop an understanding of what’s going on beneath the hood of predictive statistical models and machine learning algorithms, including those used for deep learning. \n",
    "* Hypothesize about and critically evaluate the inputs and outputs of machine learning algorithms using essential statistical tools such as the t-test, ANOVA, and R-squared. \n",
    "* Use historical data to predict the future using regression models that take advantage of frequentist statistical theory (for smaller data sets) and modern machine learning theory (for larger data sets), including why we may want to consider applying deep learning to a given problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z68nQ0ekCYhF"
   },
   "source": [
    "**Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's [Machine Learning Foundations](https://github.com/jonkrohn/ML-foundations) series, which offer detail on the following:**\n",
    "\n",
    "*Segment 1: Review of Probability Theory*\n",
    "\n",
    "* Frequentist vs Bayesian Statistics\n",
    "* Normal Distributions\n",
    "* Measures of Central Tendency \n",
    "* Quantiles\n",
    "* Variance, Standard Deviation, and Standard Error\n",
    "* Covariance and Correlation\n",
    "* The Central Limit Theorem\n",
    "\n",
    "*Segment 2: Quantifying Confidence*\n",
    "* z-scores\n",
    "* The t-test \n",
    "* p-values\n",
    "* The Bonferroni Correction for Multiple Comparisons \n",
    "* ANOVA: Analysis of Variance\n",
    "* Count Data and the Chi-Square Statistic\n",
    "* Fitting a Line to Points on a Cartesian Plane\n",
    "* The R-Squared Coefficient of Determination\n",
    "* Correlation vs Causality\n",
    "\n",
    "*Segment 3: Predicting Outcomes with Regression*\n",
    "\n",
    "* Features: Independent vs Dependent Variables\n",
    "* Linear Regression to Predict Continuous Values \n",
    "* Cost (or Loss) Functions \n",
    "* The Ordinary Least Squares Method\n",
    "* Logistic Regression to Predict Categories \n",
    "* Large Data Sets, Traditional Machine Learning, and Stochastic Gradient Descent\n",
    "* Overfitting\n",
    "* Regularization: L1 and L2\n",
    "* Deep Learning vs Frequentist Statistics\n",
    "* Resources for Further Study of Probability and Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code coming in July 2020... Watch this space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4toL+odzCdics69uQ9+W4",
   "include_colab_link": true,
   "name": "6-statistics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
